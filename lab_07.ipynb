{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonparametric Density Estimation with `condensier`\n",
    "\n",
    "## Lab 07 for PH 290: Targeted Learning in Biomedical Big Data\n",
    "\n",
    "### Author: [Nima Hejazi](https://nimahejazi.org)\n",
    "\n",
    "### Date: 28 February 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Nonparametric Density Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a moment, we will go back to simple data structures: we have observations which are realizations of univariate random variables,\n",
    "$$X_1, \\ldots, X_n \\sim F,$$\n",
    "where $F$ denotes an unknown cumulative distribution function (CDF). The goal is to estimate the distribution $F$. In particular, we are interested in estimating the density $f = F′$ , assuming that it exists.\n",
    "\n",
    "### Histograms\n",
    "\n",
    "The histogram is the oldest and most popular density estimator. We need to specify an \"origin\" $x_0$ and the class width $h$ for the specifications of the intervals:\n",
    "$$I_j =(x_0 + j \\cdot h,x_0 + (j + 1) \\cdot h),  (j = \\ldots, −1, 0, 1, \\ldots)$$\n",
    "\n",
    "### The Naïve Kernel Estimator\n",
    "\n",
    "$$\\hat{f}(x) = \\frac{1}{nh} \\sum_{i = 1}^{n} w \\left(\\frac{x - X_i}{h}\\right),$$\n",
    "where $w(x) = \\frac{1}{2}, \\mid X \\mid \\leq 1; 0, \\text{otherwise}$. This is merely a simple weight function that places a rectangular box around each interval $(x - h, x + h)$.\n",
    "\n",
    "By replaceing $w$ with a generalized smooth kernel function, we get the definition of the _kernel density estimator_:\n",
    "$$\\hat{f}(x) = \\frac{1}{nh} \\sum_{i = 1}^{n} K \\left(\\frac{x - X_i}{h}\\right),$$\n",
    "where $$K(x) \\geq 0, \\int_{-\\infty}^{\\infty} K(x) dx = 1, K(x) = K(-x).$$\n",
    "\n",
    "The positivity of the kernel function $K(\\cdot)$ guarantees a positive density estimate $f(\\cdot)$ and the normalization $K(x)dx = 1$ implies that $f(x)dx = 1$, which is necessary for $f(\\cdot)$ to be a density.\n",
    "Typically, the kernel function $K(\\cdot)$ is chosen as a probability density which is symmetric around $0$. Additionally, the smoothness of $f(\\cdot)$ is inherited from the smoothness of the kernel.\n",
    "\n",
    "In the above definition, we leave the bandwidth $h$ as a _tuning parameter_, which can be chosen so as to minimize an arbitrary distance metric that ensures the estimated function is optimal, given the available data. For large bandwidth $h$, the estimate $f(x)$ tends to be very slowly varying as a function of $x$, while small bandwidths will produce a more variable function estimate.\n",
    "\n",
    "### The Bandwidth $h$\n",
    "\n",
    "The bandwidth h is often also called the \"smoothing parameter\". It should be clear that for $h \\to 0$, we will have spikes at every observation $X_i$, whereas $f(\\cdot) = fh(\\cdot)$ becomes smoother as $h$ is increasing. In the above, we use a global bandwidth, which we might choose optimally using cross-validation, but, we can also use variable bandwidths (locally changing bandwidths $h(x)$), with the general idea her being to use a large bandwidth for regions where the data is sparse. With respect to the _bias-variance tradeoff_: **the (absolute value of the) bias of $\\hat{f}$ increases and the variance of $\\hat{f}$ decreases as $h$ increases**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (!) Exercise\n",
    "\n",
    "Propose a specific approach to choosing a locally changing bandwidth $h(x)$ for kernel density estimation. For your chosen approach, provide a single advantage and a single disadvantage for your given approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Density Estimation with `condensier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the packages we'll be using and some core project management tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(usethis)\n",
    "usethis::create_project(\".\")\n",
    "library(here)\n",
    "library(tidyverse)\n",
    "library(simcausal)\n",
    "library(condensier)\n",
    "library(sl3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by simulating a simple data set and illustrating a simple execution of how to use `condensier` to perform conditional density estimation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"simcausal\")\n",
    "D <- DAG.empty()\n",
    "D <- D + node(\"W1\", distr = \"rbern\", prob = 0.5) +\n",
    "         node(\"W2\", distr = \"rbern\", prob = 0.3) +\n",
    "         node(\"W3\", distr = \"rbern\", prob = 0.3) +\n",
    "         node(\"A.mean\", distr = \"rconst\", const = (0.98 * W1 + 0.58 * W2 + 0.33 * W3)) +\n",
    "         node(\"A\", distr = \"rnorm\", mean = A.mean, sd = 1)\n",
    "D <- set.DAG(D, n.test = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDAG(D, xjitter = 0.3, yjitter = 0.04, edge_attrs = list(width = 0.5, arrow.width = 0.4, arrow.size = 0.8), vertex_attrs = list(size = 12, label.cex = 0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've taken a look at the structure of the data-generating process (the DAG), let's generate some data and take a quick look at the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_O <- sim(D, n = 10000, rndseed = 12345)\n",
    "head(data_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdata <- data_O[seq_len(100), c(\"W1\", \"W2\", \"W3\", \"A\"), with = FALSE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've generate some data, we can try to estimate the conditional distribution $P(A \\mid W)$, using the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dens_fit <- fit_density(\n",
    "    X = c(\"W1\", \"W2\", \"W3\"), \n",
    "    Y = \"A\", \n",
    "    input_data = data_O, \n",
    "    nbins = 40, \n",
    "    bin_method = \"equal.mass\",\n",
    "    bin_estimator = speedglmR6$new())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_1 <- sample_value(model_fit = dens_fit, newdata = newdata)\n",
    "\n",
    "p1_A_given_W <- as_tibble(preds_1) %>%\n",
    "  ggplot(., aes(x = value)) +\n",
    "  geom_histogram(aes(y = ..density..), binwidth = 0.1, alpha = 0.8,\n",
    "                 position = \"identity\") +\n",
    "  geom_density(alpha = 0.2) +\n",
    "  ggtitle(\"Conditional Density: p(A | W)\") + theme_bw()\n",
    "\n",
    "p1_A_given_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dens_fit <- fit_density(\n",
    "    X = c(\"W1\", \"W2\", \"W3\"), \n",
    "    Y = \"A\", \n",
    "    input_data = data_O, \n",
    "    nbins = 30, \n",
    "    bin_method = \"equal.len\",\n",
    "    bin_estimator = speedglmR6$new())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_2 <- sample_value(model_fit = dens_fit, newdata = newdata)\n",
    "\n",
    "p2_A_given_W <- as_tibble(preds_2) %>%\n",
    "  ggplot(., aes(x = value)) +\n",
    "  geom_histogram(aes(y = ..density..), binwidth = 0.1, alpha = 0.8,\n",
    "                 position = \"identity\") +\n",
    "  geom_density(alpha = 0.2) +\n",
    "  ggtitle(\"Conditional Density: p(A | W)\") + theme_bw()\n",
    "\n",
    "p2_A_given_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dens_fit <- fit_density(\n",
    "    X = c(\"W1\", \"W2\", \"W3\"), \n",
    "    Y = \"A\", \n",
    "    input_data = data_O, \n",
    "    nbins = 25, \n",
    "    bin_method = \"dhist\",\n",
    "    bin_estimator = speedglmR6$new())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_3 <- sample_value(model_fit = dens_fit, newdata = newdata)\n",
    "\n",
    "p3_A_given_W <- as_tibble(preds_3) %>%\n",
    "  ggplot(., aes(x = value)) +\n",
    "  geom_histogram(aes(y = ..density..), binwidth = 0.1, alpha = 0.8,\n",
    "                 position = \"identity\") +\n",
    "  geom_density(alpha = 0.2) +\n",
    "  ggtitle(\"Conditional Density: p(A | W)\") + theme_bw()\n",
    "\n",
    "p3_A_given_W"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
